# Project Sentiment analysis

Проект направлен на разработку модели машинного обучения для определения тональности текста комментария к товару интернет магазина. Это позволит магазину оперативно модерировать комментарии.

# Результат:
**Разработана модель с  TF-IDF, F1 на тестовой выборке 0.935**

## Описание проекта

В рамках проекта 

## Цели проекта

- **Обучить модель классифицировать комментарии на позитивные и негативные. Имеется набор данных с разметкой о токсичности правок.**

- **Важные критерии:**
    - Метрика качества *F1* не меньше 0.75.

## Описание данных

Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.

## Стек

- `pandas`, `numpy`, `matplotlib`, `seaborn`, `wordcloud`, `scikit-learn`, `pytorch`, `transformers`, `BERT`, `LogisticRegression`, `LinearSVC`, `RandomForestClassifier`, `MultinomialNB`, `confusion_matrix`

---

## Результаты

1. **Получены данные с комментариями и целевым признаком - токсичный/нетоксичный этот коментарий. Данные без пропусков, есть дисбаланс классов (токсичных комментариев меньше).**


2. **Выбрано 2 пути предобработки текста:**
    - **В качестве бейзлайна TF-IDF vectorizer + LogisticRegression. (Проведена очиста текста, лемматизация)**
    - **Другой путь - получение эмбеддингов на предобученном BERT + LogisticRegression. (Для получения эмбеддингов текст не обрабатывался)**
    

3. **Отображены 2 облака слов для токсичного и нейтрального классов.**


4. **Проведен подбор гиперпараметров моделей. Результаты на кросс валидации:**

---F1 score для моделей с TF-IDF---

| Модель                | F1 |
|-----------------------|---------------------:|
| `LogisticRegression`       | **0.9325**            |
| `LinearSVC` | 0.9313                 |
| `RandomForestClassifier` | 0.9149               |
| `MultinomialNB`    | 0.9134               |

---F1 score для моделей с BERT---

| Модель                | F1 |
|-----------------------|---------------------:|
| `LogisticRegression`       | **0.9069**            |
| `LinearSVC` | 0.9034                 |
| `RandomForestClassifier` | 0.8907           |

---

***F1 модели LogisticRegression с TF-IDF на тестовой выборке: 0.935***

5. **F1 мера удовлетворяет условию заказчика >0.75. Модель довольно точно классифицирует нейтральные комментарии. Однако часто ошибается при классификации токсичных комментариев.**


## Рекомендации для бизнеса

    - ***Обучить модель на большем наборе данных "как есть". Займет больше времени, потребуется использование GPU.***
    - ***Подобрать более сложную модель вместо логистической регрессии - использовать нейросеть на выходном слое.***
    - ***Провести fine-tuning BERT. Это даст самый значительный прирост, однако потребуется еще больше ресурсов, чем в 1 случае.***